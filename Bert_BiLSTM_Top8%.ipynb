{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bert-pretuned/bert_model_bilstm 4/bert_model_bilstm_fold_4.h5\n",
      "/kaggle/input/bert-pretuned/bert_model_bilstm 2/bert_model_bilstm_fold_0.h5\n",
      "/kaggle/input/bert-pretuned/bert_model_bilstm 3/bert_model_bilstm_fold_2.h5\n",
      "/kaggle/input/bert-pretuned/bert_model_bilstm 5/bert_model_bilstm_fold_1.h5\n",
      "/kaggle/input/bert-pretuned/bert_model_bilstm/bert_model_bilstm_fold_3.h5\n",
      "/kaggle/input/transformers/transformers-master/.gitignore\n",
      "/kaggle/input/transformers/transformers-master/hubconf.py\n",
      "/kaggle/input/transformers/transformers-master/requirements.txt\n",
      "/kaggle/input/transformers/transformers-master/LICENSE\n",
      "/kaggle/input/transformers/transformers-master/.coveragerc\n",
      "/kaggle/input/transformers/transformers-master/MANIFEST.in\n",
      "/kaggle/input/transformers/transformers-master/requirements-dev.txt\n",
      "/kaggle/input/transformers/transformers-master/setup.py\n",
      "/kaggle/input/transformers/transformers-master/README.md\n",
      "/kaggle/input/transformers/transformers-master/CONTRIBUTING.md\n",
      "/kaggle/input/transformers/transformers-master/docs/requirements.txt\n",
      "/kaggle/input/transformers/transformers-master/docs/Makefile\n",
      "/kaggle/input/transformers/transformers-master/docs/README.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/examples.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/torchscript.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/conf.py\n",
      "/kaggle/input/transformers/transformers-master/docs/source/bertology.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/multilingual.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/migration.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/index.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/benchmarks.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/converting_tensorflow_models.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/notebooks.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/serialization.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/installation.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/quickstart.md\n",
      "/kaggle/input/transformers/transformers-master/docs/source/pretrained_models.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/Calibre-Thin.otf\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/Calibre-Light.ttf\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/code-snippets.css\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/huggingface.css\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/Calibre-Regular.otf\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/css/Calibre-Medium.otf\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/js/custom.js\n",
      "/kaggle/input/transformers/transformers-master/docs/source/_static/js/huggingface_logo.svg\n",
      "/kaggle/input/transformers/transformers-master/docs/source/main_classes/tokenizer.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/main_classes/configuration.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/main_classes/processors.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/main_classes/optimizer_schedules.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/main_classes/model.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/transformerxl.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/gpt2.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/distilbert.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/gpt.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/roberta.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/bert.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/xlnet.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/xlm.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/auto.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/model_doc/ctrl.rst\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/warmup_cosine_hard_restarts_schedule.png\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/transformers_logo_name.png\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/warmup_cosine_warm_restarts_schedule.png\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/warmup_constant_schedule.png\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/warmup_cosine_schedule.png\n",
      "/kaggle/input/transformers/transformers-master/docs/source/imgs/warmup_linear_schedule.png\n",
      "/kaggle/input/transformers/transformers-master/.circleci/config.yml\n",
      "/kaggle/input/transformers/transformers-master/.circleci/deploy.sh\n",
      "/kaggle/input/transformers/transformers-master/.github/stale.yml\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/--new-model-addition.md\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/migration.md\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/---new-benchmark.md\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/bug-report.md\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/question-help.md\n",
      "/kaggle/input/transformers/transformers-master/.github/ISSUE_TEMPLATE/feature-request.md\n",
      "/kaggle/input/transformers/transformers-master/notebooks/Comparing-TF-and-PT-models.ipynb\n",
      "/kaggle/input/transformers/transformers-master/notebooks/Comparing-PT-and-TF-models.ipynb\n",
      "/kaggle/input/transformers/transformers-master/notebooks/Comparing-TF-and-PT-models-SQuAD.ipynb\n",
      "/kaggle/input/transformers/transformers-master/notebooks/Comparing-TF-and-PT-models-MLM-NSP.ipynb\n",
      "/kaggle/input/transformers/transformers-master/docker/Dockerfile\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_xlnet.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_roberta.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_xlnet.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_camembert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/__main__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_auto.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_gpt2.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_bert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_transfo_xl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_beam_search.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_encoder_decoder.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_bert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/file_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_ctrl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_openai.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_camembert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_camembert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_xlm.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_roberta.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_xlm.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_gpt2.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_distilbert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_distilbert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_transfo_xl_utilities.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/__init__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_pytorch_checkpoint_to_tf2.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_openai.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_ctrl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_auto.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_xlm.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_transfo_xl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_roberta.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_gpt2.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_transfo_xl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_openai.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_bert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_distilbert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_xlnet.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_gpt2.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_roberta.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_ctrl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_ctrl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_distilbert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_transfo_xl_utilities.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_pytorch_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_transfo_xl.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_xlm.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/optimization.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_xlnet.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_auto.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/modeling_tf_auto.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tokenization_openai.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/configuration_bert.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_xlm_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_auto_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_xlm_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_roberta_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_roberta_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_bert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_ctrl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_encoder_decoder_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_gpt2_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_openai_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_ctrl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_tests_commons.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/optimization_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_transfo_xl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_ctrl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_roberta_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_auto_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_openai_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/__init__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_transfo_xl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_auto_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/conftest.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_xlnet_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_distilbert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_distilbert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_common_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/configuration_common_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_gpt2_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_bert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_xlnet_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_xlnet_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_common_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_distilbert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/tokenization_utils_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_openai_gpt_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_bert_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_transfo_xl_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_tf_gpt2_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/modeling_xlm_test.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/fixtures/sample_text.txt\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/fixtures/input.txt\n",
      "/kaggle/input/transformers/transformers-master/transformers/tests/fixtures/test_sentencepiece.model\n",
      "/kaggle/input/transformers/transformers-master/transformers/data/__init__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/data/metrics/__init__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/data/processors/__init__.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/data/processors/utils.py\n",
      "/kaggle/input/transformers/transformers-master/transformers/data/processors/glue.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_lm_finetuning.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_multiple_choice.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_bertology.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_tf_glue.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_summarization_finetuning.py\n",
      "/kaggle/input/transformers/transformers-master/examples/test_examples.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_generation.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_squad_evaluate.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_summarization.py\n",
      "/kaggle/input/transformers/transformers-master/examples/requirements.txt\n",
      "/kaggle/input/transformers/transformers-master/examples/run_multiple_choice.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_summarization_test.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_ner.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_ner.py\n",
      "/kaggle/input/transformers/transformers-master/examples/run_squad.py\n",
      "/kaggle/input/transformers/transformers-master/examples/benchmarks.py\n",
      "/kaggle/input/transformers/transformers-master/examples/README.md\n",
      "/kaggle/input/transformers/transformers-master/examples/run_glue.py\n",
      "/kaggle/input/transformers/transformers-master/examples/utils_squad.py\n",
      "/kaggle/input/transformers/transformers-master/examples/tests_samples/.gitignore\n",
      "/kaggle/input/transformers/transformers-master/examples/tests_samples/MRPC/train.tsv\n",
      "/kaggle/input/transformers/transformers-master/examples/tests_samples/MRPC/dev.tsv\n",
      "/kaggle/input/transformers/transformers-master/examples/tests_samples/SQUAD/dev-v2.0-small.json\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/distiller.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/train.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/run_squad_w_distillation.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/lm_seqs_dataset.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/utils.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/requirements.txt\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/README.md\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/grouped_batch_sampler.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/training_configs/distilbert-base-uncased.json\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/training_configs/distilgpt2.json\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/scripts/token_counts.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/scripts/extract_distilbert.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/scripts/binarized_data.py\n",
      "/kaggle/input/transformers/transformers-master/examples/distillation/scripts/extract.py\n",
      "/kaggle/input/transformers/transformers-master/examples/contrib/run_transfo_xl.py\n",
      "/kaggle/input/transformers/transformers-master/examples/contrib/run_camembert.py\n",
      "/kaggle/input/transformers/transformers-master/examples/contrib/run_openai_gpt.py\n",
      "/kaggle/input/transformers/transformers-master/examples/contrib/run_swag.py\n",
      "/kaggle/input/transformers/transformers-master/examples/contrib/README.md\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_example_script/utils_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_example_script/run_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_example_script/README.md\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/tokenization_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/configuration_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/convert_xxx_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/README.md\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/modeling_tf_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/modeling_xxx.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/tests/modeling_tf_xxx_test.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/tests/tokenization_xxx_test.py\n",
      "/kaggle/input/transformers/transformers-master/templates/adding_a_new_model/tests/modeling_xxx_test.py\n",
      "/kaggle/input/google-quest-challenge/test.csv\n",
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/sacremoses/sacremoses-master/.travis.yml\n",
      "/kaggle/input/sacremoses/sacremoses-master/requirements.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/.appveyor.yml\n",
      "/kaggle/input/sacremoses/sacremoses-master/CONTRIBUTORS.md\n",
      "/kaggle/input/sacremoses/sacremoses-master/setup.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/README.md\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/tokenize.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/subwords.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/normalize.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/chinese.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/cli.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/__init__.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/truecase.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/corpus.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/util.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/test/test_tokenizer.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/test/test_normalizer.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/test/test_truecaser.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/test/test_corpus.py\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Titlecase_Letter.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsAlpha-unichars-au.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsAlnum.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Katakana.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Symbol.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Number.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Hiragana.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsPf.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Uppercase_Letter.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Lowercase_Letter.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsAlpha.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Han.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsLower.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Separator.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Hangul_Syllables.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Currency_Symbol.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Open_Punctuation.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsPi.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Punctuation.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Line_Separator.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsAlnum-unichars-au.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsUpper.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsN.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/CJK.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Close_Punctuation.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/CJKSymbols.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsSc.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/Hangul.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/perluniprops/IsSo.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.nl\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.lv\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.pt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sl\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ta\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.fr\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sk\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ru\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ro\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.el\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.is\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.zh\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.hu\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.pl\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.de\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.cs\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.en\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/README.txt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.es\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ga\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.sv\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.lt\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.fi\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.it\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.yue\n",
      "/kaggle/input/sacremoses/sacremoses-master/sacremoses/data/nonbreaking_prefixes/nonbreaking_prefix.ca\n",
      "/kaggle/input/bert-uncased/saved_model.pb\n",
      "/kaggle/input/bert-uncased/assets/vocab.txt\n",
      "/kaggle/input/bert-uncased/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/bert-uncased/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input/google-quest-challenge/'\n",
    "BERT_PATH = '../input/bert-uncased/'\n",
    "tokenizer = tokenization.FullTokenizer('../input/bert-uncased/assets/vocab.txt', True)\n",
    "MAX_SEQUENCE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_categories = list(df_train.columns[11:])\n",
    "input_categories = list(df_train.columns[[1,2,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    first_sep = True\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            if first_sep:\n",
    "                first_sep = False \n",
    "            else:\n",
    "                current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids\n",
    "\n",
    "def _trim_input(title, question, answer, max_sequence_length, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239):\n",
    "\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+4) > max_sequence_length:\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+4 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+4)))\n",
    "        \n",
    "        t = t[:t_new_len]\n",
    "        q = q[:q_new_len]\n",
    "        a = a[:a_new_len]\n",
    "    \n",
    "    return t, q, a\n",
    "\n",
    "def _convert_to_bert_inputs(title, question, answer, tokenizer, max_sequence_length):\n",
    "    \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "    stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + question + [\"[SEP]\"] + answer + [\"[SEP]\"]\n",
    "\n",
    "    input_ids = _get_ids(stoken, tokenizer, max_sequence_length)\n",
    "    input_masks = _get_masks(stoken, max_sequence_length)\n",
    "    input_segments = _get_segments(stoken, max_sequence_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "def compute_input_arays(df, columns, tokenizer, max_sequence_length):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for _, instance in tqdm(df[columns].iterrows()):\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "        t, q, a = _trim_input(t, q, a, max_sequence_length)\n",
    "\n",
    "        ids, masks, segments = _convert_to_bert_inputs(t, q, a, tokenizer, max_sequence_length)\n",
    "        input_ids.append(ids)\n",
    "        input_masks.append(masks)\n",
    "        input_segments.append(segments)\n",
    "        \n",
    "    return [np.asarray(input_ids, dtype=np.int32), \n",
    "            np.asarray(input_masks, dtype=np.int32), \n",
    "            np.asarray(input_segments, dtype=np.int32)]\n",
    "\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_trues, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data, batch_size=16, fold=None):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if self.fold is not None:\n",
    "            self.model.save_weights(f'bert-base-{fold}-{epoch}.h5py')\n",
    "        \n",
    "        self.test_predictions.append(\n",
    "            self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "        )\n",
    "\n",
    "def bert_model():\n",
    "    \n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_word_ids')\n",
    "    input_masks = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "    input_segments = tf.keras.layers.Input(\n",
    "        (MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(BERT_PATH, trainable=True)\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_masks, input_segments])\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(768, return_sequences=True))(sequence_output)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(768))(x)\n",
    "    # x = tf.keras.layers.concatenate([x, input_features])\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_word_ids, input_masks, input_segments], outputs=out)\n",
    "    \n",
    "    return model     \n",
    "        \n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold):\n",
    "        \n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=None)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729fc791f2794f12815f939c22feec5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body)\n",
    "\n",
    "# outputs = compute_output_arrays(df_train, output_categories)\n",
    "# inputs = compute_input_arays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "test_inputs = compute_input_arays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histories = []\n",
    "# for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    \n",
    "#     # will actually only do 3 folds (out of 5) to manage < 2h\n",
    "#     K.clear_session()\n",
    "#     model = bert_model()\n",
    "\n",
    "#     train_inputs = [inputs[i][train_idx] for i in range(3)]\n",
    "#     train_outputs = outputs[train_idx]\n",
    "\n",
    "#     valid_inputs = [inputs[i][valid_idx] for i in range(3)]\n",
    "#     valid_outputs = outputs[valid_idx]\n",
    "\n",
    "#     # history contains two lists of valid and test preds respectively:\n",
    "#     #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "#     history = train_and_predict(model, \n",
    "#                       train_data=(train_inputs, train_outputs), \n",
    "#                       valid_data=(valid_inputs, valid_outputs),\n",
    "#                       test_data=test_inputs, \n",
    "#                       learning_rate=3e-5, epochs=4, batch_size=8,\n",
    "#                       loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "#     histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_path1 = f'../input/bert-pretuned/bert_model_bilstm/bert_model_bilstm_fold_3.h5'\n",
    "model_path2 = f'../input/bert-pretuned/bert_model_bilstm 2/bert_model_bilstm_fold_0.h5'\n",
    "model_path3 = f'../input/bert-pretuned/bert_model_bilstm 3/bert_model_bilstm_fold_2.h5'\n",
    "model_path4 = f'../input/bert-pretuned/bert_model_bilstm 4/bert_model_bilstm_fold_4.h5'\n",
    "model_path5 = f'../input/bert-pretuned/bert_model_bilstm 5/bert_model_bilstm_fold_1.h5'\n",
    "#print(model_path)\n",
    "model = bert_model()\n",
    "model.load_weights(model_path1)\n",
    "models.append(model)\n",
    "\n",
    "model = bert_model()\n",
    "model.load_weights(model_path2)\n",
    "models.append(model)\n",
    "\n",
    "model = bert_model()\n",
    "model.load_weights(model_path3)\n",
    "models.append(model)\n",
    "\n",
    "model = bert_model()\n",
    "model.load_weights(model_path4)\n",
    "models.append(model)\n",
    "\n",
    "model = bert_model()\n",
    "model.load_weights(model_path5)\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476/476 [==============================] - 23s 49ms/sample\n",
      "476/476 [==============================] - 20s 42ms/sample\n",
      "476/476 [==============================] - 20s 42ms/sample\n",
      "476/476 [==============================] - 21s 43ms/sample\n",
      "476/476 [==============================] - 20s 42ms/sample\n"
     ]
    }
   ],
   "source": [
    "test_predictions = []\n",
    "for model in models:\n",
    "    test_predictions.append(model.predict(test_inputs, batch_size=8, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = np.mean(test_predictions, axis=0)\n",
    "df_sub.iloc[:, 1:] = final_predictions\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# # model.layers[3].trainable = False\n",
    "# # x = tf.keras.layers.GlobalAveragePooling1D()(model.layers[3].output[1])\n",
    "# # x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# # out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "# # new_model = tf.keras.models.Model(inputs=model.inputs, outputs=out)\n",
    "# # new_model.load_weights(model_path)\n",
    "\n",
    "# model_path = f'../input/bert-bilstm/bert_model_fold_1.h5'\n",
    "# #print(model_path)\n",
    "# model = bert_model()\n",
    "# model.load_weights(model_path)\n",
    "# model.layers[3].trainable = False\n",
    "# x = tf.keras.layers.GlobalAveragePooling1D()(model.layers[3].output[1])\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "# new_model = tf.keras.models.Model(inputs=model.inputs, outputs=out)\n",
    "# # new_model.load_weights(model_path)\n",
    "# #model = load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer}) \n",
    "# #reloaded_model = tf.keras.experimental.load_from_saved_model('path_to_my_model.h5', custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "# models.append(new_model)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(3,15):\n",
    "#     model_path = f'../input/bert-bilstm/bert_model_fold_{i}.h5'\n",
    "#     #print(model_path)\n",
    "#     model = bert_model()\n",
    "#     model.load_weights(model_path)\n",
    "#     model.layers[3].trainable = False\n",
    "#     x = tf.keras.layers.GlobalAveragePooling1D()(model.layers[3].output[1])\n",
    "#     x = tf.keras.layers.Dropout(0.2)(x)\n",
    "#     out = tf.keras.layers.Dense(30, activation=\"sigmoid\", name=\"dense_output\")(x)\n",
    "#     new_model = tf.keras.models.Model(inputs=model.inputs, outputs=out)\n",
    "# #     new_model.load_weights(model_path)\n",
    "#     #model = load_model(model_path, custom_objects={'KerasLayer':hub.KerasLayer}) \n",
    "#     #reloaded_model = tf.keras.experimental.load_from_saved_model('path_to_my_model.h5', custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "#     models.append(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = np.mean(test_predictions, axis=0)\n",
    "df_sub.iloc[:, 1:] = final_predictions\n",
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = [histories[0].test_predictions for i in range(len(histories))]\n",
    "# test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "# test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "# df_sub.iloc[:, 1:] = test_predictions\n",
    "\n",
    "# df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02a47d4d9f2b4fffa0e46e60cf506c96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3d9fd914f6e446cd96b91350d7b7279e",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9676e1d2352c4826b63f64f29cb5ee38",
       "value": 1
      }
     },
     "3d9fd914f6e446cd96b91350d7b7279e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5dc87b2d4d624f5fbfdfb719d86c8391": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6ca4f7bf90d643ad95ca9eeb517df541": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "729fc791f2794f12815f939c22feec5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_02a47d4d9f2b4fffa0e46e60cf506c96",
        "IPY_MODEL_9b52dcf9baa04a479187e14f6c7940d8"
       ],
       "layout": "IPY_MODEL_6ca4f7bf90d643ad95ca9eeb517df541"
      }
     },
     "96072830bd804237b2bfb0a5855573b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9676e1d2352c4826b63f64f29cb5ee38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9b52dcf9baa04a479187e14f6c7940d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_96072830bd804237b2bfb0a5855573b9",
       "placeholder": "",
       "style": "IPY_MODEL_5dc87b2d4d624f5fbfdfb719d86c8391",
       "value": " 476/? [00:05&lt;00:00, 86.94it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
